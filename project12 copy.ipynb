{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score , root_mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U --user scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/Tripleten/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BORRADOR , NO MANTENER\n",
    "\n",
    "# df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334064</th>\n",
       "      <td>27/03/2016 21:58</td>\n",
       "      <td>1799</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>auto</td>\n",
       "      <td>61</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>70000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>smart</td>\n",
       "      <td>no</td>\n",
       "      <td>27/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>47652</td>\n",
       "      <td>31/03/2016 05:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305293</th>\n",
       "      <td>19/03/2016 14:45</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>astra</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>88255</td>\n",
       "      <td>30/03/2016 07:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176627</th>\n",
       "      <td>31/03/2016 12:55</td>\n",
       "      <td>4250</td>\n",
       "      <td>suv</td>\n",
       "      <td>2001</td>\n",
       "      <td>auto</td>\n",
       "      <td>218</td>\n",
       "      <td>m_klasse</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>25421</td>\n",
       "      <td>06/04/2016 05:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22853</th>\n",
       "      <td>25/03/2016 13:58</td>\n",
       "      <td>1600</td>\n",
       "      <td>wagon</td>\n",
       "      <td>1999</td>\n",
       "      <td>manual</td>\n",
       "      <td>136</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>bmw</td>\n",
       "      <td>yes</td>\n",
       "      <td>25/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>75031</td>\n",
       "      <td>25/03/2016 13:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "334064  27/03/2016 21:58   1799       small              2001    auto     61   \n",
       "305293  19/03/2016 14:45    100         NaN              1995     NaN      0   \n",
       "176627  31/03/2016 12:55   4250         suv              2001    auto    218   \n",
       "22853   25/03/2016 13:58   1600       wagon              1999  manual    136   \n",
       "\n",
       "           Model  Mileage  RegistrationMonth  FuelType          Brand  \\\n",
       "334064    fortwo    70000                  6    petrol          smart   \n",
       "305293     astra   150000                  7    petrol           opel   \n",
       "176627  m_klasse   150000                  6    petrol  mercedes_benz   \n",
       "22853        3er   150000                 12  gasoline            bmw   \n",
       "\n",
       "       NotRepaired       DateCreated  NumberOfPictures  PostalCode  \\\n",
       "334064          no  27/03/2016 00:00                 0       47652   \n",
       "305293         NaN  19/03/2016 00:00                 0       88255   \n",
       "176627          no  31/03/2016 00:00                 0       25421   \n",
       "22853          yes  25/03/2016 00:00                 0       75031   \n",
       "\n",
       "                LastSeen  \n",
       "334064  31/03/2016 05:47  \n",
       "305293  30/03/2016 07:45  \n",
       "176627  06/04/2016 05:44  \n",
       "22853   25/03/2016 13:58  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombrado columnas para mantener formato Snake_Case en el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "snake_case_cols = []\n",
    "\n",
    "for col in cols:\n",
    "    snake_case_col = '_'.join(re.findall(r'[A-Z][a-z0-9]*', col)).lower()\n",
    "    snake_case_cols.append(snake_case_col)\n",
    "\n",
    "# print(snake_case_cols)\n",
    "df.columns = snake_case_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniendo información general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146088</th>\n",
       "      <td>07/03/2016 12:36</td>\n",
       "      <td>850</td>\n",
       "      <td>small</td>\n",
       "      <td>1998</td>\n",
       "      <td>auto</td>\n",
       "      <td>65</td>\n",
       "      <td>corsa</td>\n",
       "      <td>150000</td>\n",
       "      <td>9</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>no</td>\n",
       "      <td>07/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>51580</td>\n",
       "      <td>05/04/2016 13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71187</th>\n",
       "      <td>09/03/2016 15:38</td>\n",
       "      <td>1400</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2004</td>\n",
       "      <td>manual</td>\n",
       "      <td>136</td>\n",
       "      <td>c5</td>\n",
       "      <td>150000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>citroen</td>\n",
       "      <td>no</td>\n",
       "      <td>09/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36269</td>\n",
       "      <td>09/03/2016 15:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22869</th>\n",
       "      <td>04/04/2016 22:39</td>\n",
       "      <td>4400</td>\n",
       "      <td>bus</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>68</td>\n",
       "      <td>transporter</td>\n",
       "      <td>80000</td>\n",
       "      <td>12</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/04/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>37081</td>\n",
       "      <td>07/04/2016 01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25202</th>\n",
       "      <td>26/03/2016 17:25</td>\n",
       "      <td>7900</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2007</td>\n",
       "      <td>manual</td>\n",
       "      <td>105</td>\n",
       "      <td>golf</td>\n",
       "      <td>90000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>26/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65719</td>\n",
       "      <td>31/03/2016 21:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342165</th>\n",
       "      <td>06/03/2016 14:36</td>\n",
       "      <td>4111</td>\n",
       "      <td>small</td>\n",
       "      <td>2006</td>\n",
       "      <td>manual</td>\n",
       "      <td>101</td>\n",
       "      <td>fabia</td>\n",
       "      <td>125000</td>\n",
       "      <td>2</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>06/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9599</td>\n",
       "      <td>26/03/2016 20:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_crawled  price vehicle_type  registration_year gearbox  \\\n",
       "146088  07/03/2016 12:36    850        small               1998    auto   \n",
       "71187   09/03/2016 15:38   1400        wagon               2004  manual   \n",
       "22869   04/04/2016 22:39   4400          bus               2001  manual   \n",
       "25202   26/03/2016 17:25   7900        sedan               2007  manual   \n",
       "342165  06/03/2016 14:36   4111        small               2006  manual   \n",
       "\n",
       "        power        model  mileage  registration_month fuel_type       brand  \\\n",
       "146088     65        corsa   150000                   9    petrol        opel   \n",
       "71187     136           c5   150000                   4       NaN     citroen   \n",
       "22869      68  transporter    80000                  12  gasoline  volkswagen   \n",
       "25202     105         golf    90000                   5  gasoline  volkswagen   \n",
       "342165    101        fabia   125000                   2  gasoline       skoda   \n",
       "\n",
       "       not_repaired      date_created  number_of_pictures  postal_code  \\\n",
       "146088           no  07/03/2016 00:00                   0        51580   \n",
       "71187            no  09/03/2016 00:00                   0        36269   \n",
       "22869           NaN  04/04/2016 00:00                   0        37081   \n",
       "25202            no  26/03/2016 00:00                   0        65719   \n",
       "342165           no  06/03/2016 00:00                   0         9599   \n",
       "\n",
       "               last_seen  \n",
       "146088  05/04/2016 13:15  \n",
       "71187   09/03/2016 15:38  \n",
       "22869   07/04/2016 01:16  \n",
       "25202   31/03/2016 21:44  \n",
       "342165  26/03/2016 20:18  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   date_crawled        354369 non-null  object\n",
      " 1   price               354369 non-null  int64 \n",
      " 2   vehicle_type        316879 non-null  object\n",
      " 3   registration_year   354369 non-null  int64 \n",
      " 4   gearbox             334536 non-null  object\n",
      " 5   power               354369 non-null  int64 \n",
      " 6   model               334664 non-null  object\n",
      " 7   mileage             354369 non-null  int64 \n",
      " 8   registration_month  354369 non-null  int64 \n",
      " 9   fuel_type           321474 non-null  object\n",
      " 10  brand               354369 non-null  object\n",
      " 11  not_repaired        283215 non-null  object\n",
      " 12  date_created        354369 non-null  object\n",
      " 13  number_of_pictures  354369 non-null  int64 \n",
      " 14  postal_code         354369 non-null  int64 \n",
      " 15  last_seen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resaltando columnas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values by column:\n",
      "vehicle_type    37490\n",
      "gearbox         19833\n",
      "model           19705\n",
      "fuel_type       32895\n",
      "not_repaired    71154\n",
      "dtype: int64\n",
      "\n",
      "Total null rows: 108555\n"
     ]
    }
   ],
   "source": [
    "null_values = df.isna().sum()\n",
    "null_rows= df.shape[0] - df.dropna().shape[0]\n",
    "\n",
    "null_values = null_values[null_values>0]\n",
    "\n",
    "\n",
    "print(f'Null values by column:')\n",
    "print(null_values, end='\\n\\n')\n",
    "print(f'Total null rows: {null_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando si tenemos valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_rows = df.duplicated()\n",
    "duplicated_rows.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinando manualmente un caso para verificar coherencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>21/03/2016 19:06</td>\n",
       "      <td>5999</td>\n",
       "      <td>small</td>\n",
       "      <td>2009</td>\n",
       "      <td>manual</td>\n",
       "      <td>80</td>\n",
       "      <td>polo</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>21/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65529</td>\n",
       "      <td>05/04/2016 20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14266</th>\n",
       "      <td>21/03/2016 19:06</td>\n",
       "      <td>5999</td>\n",
       "      <td>small</td>\n",
       "      <td>2009</td>\n",
       "      <td>manual</td>\n",
       "      <td>80</td>\n",
       "      <td>polo</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>21/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65529</td>\n",
       "      <td>05/04/2016 20:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_crawled  price vehicle_type  registration_year gearbox  power  \\\n",
       "183    21/03/2016 19:06   5999        small               2009  manual     80   \n",
       "14266  21/03/2016 19:06   5999        small               2009  manual     80   \n",
       "\n",
       "      model  mileage  registration_month fuel_type       brand not_repaired  \\\n",
       "183    polo   125000                   5    petrol  volkswagen           no   \n",
       "14266  polo   125000                   5    petrol  volkswagen           no   \n",
       "\n",
       "           date_created  number_of_pictures  postal_code         last_seen  \n",
       "183    21/03/2016 00:00                   0        65529  05/04/2016 20:47  \n",
       "14266  21/03/2016 00:00                   0        65529  05/04/2016 20:47  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['date_crawled'] == '21/03/2016 19:06') & (df['price']== 5999)]\n",
    "# df.query(\"date_crawled == '21/03/2016 19:06' and price == 5999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "\n",
    "- Elementos con clasificaciones Dtype erroneos (price, not_repaired, date_crawled, last_seen)\n",
    "- Elementos nulos para las columnas (vehicle_type, gearbox, model, fuel_type, not_repaired)\n",
    "- 262 elementos duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reasignaran los tipos de valor date_crawled y last_seen al formato datetime64, se evitará reasignar los tipos de valor de price y not_repaired debido a sus valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_crawled'] = pd.to_datetime(df['date_crawled'], format='%d/%m/%Y %H:%M')\n",
    "df['last_seen'] = pd.to_datetime(df['last_seen'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "print(df['date_crawled'].dt.year.unique() == df['last_seen'].dt.year.unique())\n",
    "# print(df['date_crawled'].dt.month.sort_values().unique() == df['last_seen'].dt.month.sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificamos la columna 'not_repaired' a booleano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm_he\\AppData\\Local\\Temp\\ipykernel_7888\\2027442455.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['not_repaired'].replace({'yes':1, 'no':0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "df['not_repaired'].replace({'yes':1, 'no':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos pertenecen al 2016 y las columnas date_crawled y last seen tiene los mismo resultados a nivel año y mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a eliminar los valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearé una función que me permita analizar de una manera visuallos elementos únicos que se encuentran dentro de mis columnas, para verificar si existen datos erroneos o extraños.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(db):\n",
    "    obj = db.select_dtypes(include='object').columns\n",
    "    int = db.select_dtypes(include='int').columns\n",
    "    \n",
    "    print('Analisis de elementos Object')\n",
    "    for i in obj:\n",
    "\n",
    "        print(f'Elementos de la columna {i}')\n",
    "        print(db[i].sort_values().unique(), end='\\n\\n')\n",
    "\n",
    "    for i in int:\n",
    "\n",
    "        print(f'Elementos de la columna {i}')\n",
    "        print(db[i].sort_values().unique(), end='\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisis de elementos Object\n",
      "Elementos de la columna vehicle_type\n",
      "['bus' 'convertible' 'coupe' 'other' 'sedan' 'small' 'suv' 'wagon' nan]\n",
      "\n",
      "Elementos de la columna gearbox\n",
      "['auto' 'manual' nan]\n",
      "\n",
      "Elementos de la columna model\n",
      "['100' '145' '147' '156' '159' '1_reihe' '1er' '200' '2_reihe' '300c'\n",
      " '3_reihe' '3er' '4_reihe' '500' '5_reihe' '5er' '601' '6_reihe' '6er'\n",
      " '7er' '80' '850' '90' '900' '9000' '911' 'a1' 'a2' 'a3' 'a4' 'a5' 'a6'\n",
      " 'a8' 'a_klasse' 'accord' 'agila' 'alhambra' 'almera' 'altea' 'amarok'\n",
      " 'antara' 'arosa' 'astra' 'auris' 'avensis' 'aveo' 'aygo' 'b_klasse'\n",
      " 'b_max' 'beetle' 'berlingo' 'bora' 'boxster' 'bravo' 'c1' 'c2' 'c3' 'c4'\n",
      " 'c5' 'c_klasse' 'c_max' 'c_reihe' 'caddy' 'calibra' 'captiva' 'carisma'\n",
      " 'carnival' 'cayenne' 'cc' 'ceed' 'charade' 'cherokee' 'citigo' 'civic'\n",
      " 'cl' 'clio' 'clk' 'clubman' 'colt' 'combo' 'cooper' 'cordoba' 'corolla'\n",
      " 'corsa' 'cr_reihe' 'croma' 'crossfire' 'cuore' 'cx_reihe' 'defender'\n",
      " 'delta' 'discovery' 'doblo' 'ducato' 'duster' 'e_klasse' 'elefantino'\n",
      " 'eos' 'escort' 'espace' 'exeo' 'fabia' 'fiesta' 'focus' 'forester'\n",
      " 'forfour' 'fortwo' 'fox' 'freelander' 'fusion' 'g_klasse' 'galant'\n",
      " 'galaxy' 'getz' 'gl' 'glk' 'golf' 'grand' 'i3' 'i_reihe' 'ibiza'\n",
      " 'impreza' 'insignia' 'jazz' 'jetta' 'jimny' 'juke' 'justy' 'ka' 'kadett'\n",
      " 'kaefer' 'kalina' 'kalos' 'kangoo' 'kappa' 'kuga' 'laguna' 'lancer'\n",
      " 'lanos' 'legacy' 'leon' 'lodgy' 'logan' 'lupo' 'lybra' 'm_klasse'\n",
      " 'm_reihe' 'materia' 'matiz' 'megane' 'meriva' 'micra' 'mii' 'modus'\n",
      " 'mondeo' 'move' 'musa' 'mustang' 'mx_reihe' 'navara' 'niva' 'note'\n",
      " 'nubira' 'octavia' 'omega' 'one' 'other' 'outlander' 'pajero' 'panda'\n",
      " 'passat' 'phaeton' 'picanto' 'polo' 'primera' 'ptcruiser' 'punto' 'q3'\n",
      " 'q5' 'q7' 'qashqai' 'r19' 'range_rover' 'range_rover_evoque'\n",
      " 'range_rover_sport' 'rangerover' 'rav' 'rio' 'roadster' 'roomster'\n",
      " 'rx_reihe' 's60' 's_klasse' 's_max' 's_type' 'samara' 'sandero' 'santa'\n",
      " 'scenic' 'scirocco' 'seicento' 'serie_1' 'serie_2' 'serie_3' 'sharan'\n",
      " 'signum' 'sirion' 'sl' 'slk' 'sorento' 'spark' 'spider' 'sportage'\n",
      " 'sprinter' 'stilo' 'superb' 'swift' 'terios' 'tigra' 'tiguan' 'toledo'\n",
      " 'touareg' 'touran' 'transit' 'transporter' 'tt' 'tucson' 'twingo' 'up'\n",
      " 'v40' 'v50' 'v60' 'v70' 'v_klasse' 'vectra' 'verso' 'viano' 'vito'\n",
      " 'vivaro' 'voyager' 'wrangler' 'x_reihe' 'x_trail' 'x_type' 'xc_reihe'\n",
      " 'yaris' 'yeti' 'ypsilon' 'z_reihe' 'zafira' nan]\n",
      "\n",
      "Elementos de la columna fuel_type\n",
      "['cng' 'electric' 'gasoline' 'hybrid' 'lpg' 'other' 'petrol' nan]\n",
      "\n",
      "Elementos de la columna brand\n",
      "['alfa_romeo' 'audi' 'bmw' 'chevrolet' 'chrysler' 'citroen' 'dacia'\n",
      " 'daewoo' 'daihatsu' 'fiat' 'ford' 'honda' 'hyundai' 'jaguar' 'jeep' 'kia'\n",
      " 'lada' 'lancia' 'land_rover' 'mazda' 'mercedes_benz' 'mini' 'mitsubishi'\n",
      " 'nissan' 'opel' 'peugeot' 'porsche' 'renault' 'rover' 'saab' 'seat'\n",
      " 'skoda' 'smart' 'sonstige_autos' 'subaru' 'suzuki' 'toyota' 'trabant'\n",
      " 'volkswagen' 'volvo']\n",
      "\n",
      "Elementos de la columna not_repaired\n",
      "[0 1 nan]\n",
      "\n",
      "Elementos de la columna date_created\n",
      "['01/02/2016 00:00' '01/03/2016 00:00' '01/04/2016 00:00'\n",
      " '02/01/2016 00:00' '02/02/2016 00:00' '02/03/2016 00:00'\n",
      " '02/04/2016 00:00' '02/11/2015 00:00' '03/01/2016 00:00'\n",
      " '03/02/2016 00:00' '03/03/2016 00:00' '03/04/2016 00:00'\n",
      " '04/02/2016 00:00' '04/03/2016 00:00' '04/04/2016 00:00'\n",
      " '04/09/2015 00:00' '05/02/2016 00:00' '05/03/2016 00:00'\n",
      " '05/04/2016 00:00' '05/12/2015 00:00' '06/01/2016 00:00'\n",
      " '06/02/2016 00:00' '06/03/2016 00:00' '06/04/2016 00:00'\n",
      " '06/12/2015 00:00' '07/01/2016 00:00' '07/02/2016 00:00'\n",
      " '07/03/2016 00:00' '07/04/2016 00:00' '07/08/2015 00:00'\n",
      " '08/01/2016 00:00' '08/02/2016 00:00' '08/03/2016 00:00'\n",
      " '08/11/2015 00:00' '09/02/2016 00:00' '09/03/2016 00:00'\n",
      " '09/09/2015 00:00' '10/01/2016 00:00' '10/02/2016 00:00'\n",
      " '10/03/2014 00:00' '10/03/2016 00:00' '10/08/2015 00:00'\n",
      " '10/11/2015 00:00' '11/02/2016 00:00' '11/03/2016 00:00'\n",
      " '12/02/2016 00:00' '12/03/2016 00:00' '12/11/2015 00:00'\n",
      " '13/01/2016 00:00' '13/02/2016 00:00' '13/03/2016 00:00'\n",
      " '14/02/2016 00:00' '14/03/2016 00:00' '15/01/2016 00:00'\n",
      " '15/02/2016 00:00' '15/03/2016 00:00' '16/01/2016 00:00'\n",
      " '16/02/2016 00:00' '16/03/2016 00:00' '17/01/2016 00:00'\n",
      " '17/02/2016 00:00' '17/03/2016 00:00' '17/11/2015 00:00'\n",
      " '17/12/2015 00:00' '18/01/2016 00:00' '18/02/2016 00:00'\n",
      " '18/03/2016 00:00' '18/06/2015 00:00' '19/01/2016 00:00'\n",
      " '19/02/2016 00:00' '19/03/2016 00:00' '20/01/2016 00:00'\n",
      " '20/02/2016 00:00' '20/03/2015 00:00' '20/03/2016 00:00'\n",
      " '21/02/2016 00:00' '21/03/2016 00:00' '22/01/2016 00:00'\n",
      " '22/02/2016 00:00' '22/03/2016 00:00' '23/01/2016 00:00'\n",
      " '23/02/2016 00:00' '23/03/2016 00:00' '23/11/2015 00:00'\n",
      " '24/01/2016 00:00' '24/02/2016 00:00' '24/03/2016 00:00'\n",
      " '24/11/2015 00:00' '25/01/2016 00:00' '25/02/2016 00:00'\n",
      " '25/03/2016 00:00' '26/01/2016 00:00' '26/02/2016 00:00'\n",
      " '26/03/2016 00:00' '27/01/2016 00:00' '27/02/2016 00:00'\n",
      " '27/03/2016 00:00' '27/12/2015 00:00' '28/01/2016 00:00'\n",
      " '28/02/2016 00:00' '28/03/2016 00:00' '29/01/2016 00:00'\n",
      " '29/02/2016 00:00' '29/03/2016 00:00' '30/01/2016 00:00'\n",
      " '30/03/2016 00:00' '30/12/2015 00:00' '31/01/2016 00:00'\n",
      " '31/03/2016 00:00']\n",
      "\n",
      "Elementos de la columna price\n",
      "[    0     1     2 ... 19998 19999 20000]\n",
      "\n",
      "Elementos de la columna registration_year\n",
      "[1000 1001 1039 1111 1200 1234 1253 1255 1300 1400 1500 1600 1602 1688\n",
      " 1800 1910 1915 1919 1920 1923 1925 1927 1928 1929 1930 1931 1932 1933\n",
      " 1934 1935 1936 1937 1938 1940 1941 1942 1943 1944 1945 1946 1947 1948\n",
      " 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962\n",
      " 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976\n",
      " 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990\n",
      " 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004\n",
      " 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018\n",
      " 2019 2066 2200 2222 2290 2500 2800 2900 3000 3200 3500 3700 3800 4000\n",
      " 4100 4500 4800 5000 5300 5555 5600 5900 5911 6000 6500 7000 7100 7500\n",
      " 7800 8000 8200 8455 8500 8888 9000 9229 9450 9996 9999]\n",
      "\n",
      "Elementos de la columna power\n",
      "[    0     1     2     3     4     5     6     7     8     9    10    11\n",
      "    12    13    14    15    16    17    18    19    20    21    22    23\n",
      "    24    25    26    27    28    29    30    31    32    33    34    35\n",
      "    36    37    38    39    40    41    42    43    44    45    46    47\n",
      "    48    49    50    51    52    53    54    55    56    57    58    59\n",
      "    60    61    62    63    64    65    66    67    68    69    70    71\n",
      "    72    73    74    75    76    77    78    79    80    81    82    83\n",
      "    84    85    86    87    88    89    90    91    92    93    94    95\n",
      "    96    97    98    99   100   101   102   103   104   105   106   107\n",
      "   108   109   110   111   112   113   114   115   116   117   118   119\n",
      "   120   121   122   123   124   125   126   127   128   129   130   131\n",
      "   132   133   134   135   136   137   138   139   140   141   142   143\n",
      "   144   145   146   147   148   149   150   151   152   153   154   155\n",
      "   156   157   158   159   160   161   162   163   164   165   166   167\n",
      "   168   169   170   171   172   173   174   175   176   177   178   179\n",
      "   180   181   182   183   184   185   186   187   188   189   190   191\n",
      "   192   193   194   195   196   197   198   199   200   201   202   203\n",
      "   204   205   206   207   208   209   210   211   212   213   214   215\n",
      "   216   217   218   219   220   221   222   223   224   225   226   227\n",
      "   228   229   230   231   232   233   234   235   236   237   238   239\n",
      "   240   241   242   243   244   245   246   247   248   249   250   251\n",
      "   252   253   254   255   256   257   258   259   260   261   262   264\n",
      "   265   266   267   268   269   270   271   272   273   274   275   276\n",
      "   277   278   279   280   281   282   283   284   285   286   287   288\n",
      "   289   290   292   293   294   295   296   297   298   299   300   301\n",
      "   303   304   305   306   307   308   309   310   311   313   314   315\n",
      "   316   317   318   320   321   322   323   324   325   326   327   328\n",
      "   329   330   331   332   333   334   335   336   337   338   339   340\n",
      "   341   343   344   345   346   347   348   349   350   351   352   353\n",
      "   354   355   356   357   358   360   361   362   363   364   365   367\n",
      "   368   370   371   374   375   376   377   379   380   381   382   385\n",
      "   386   387   388   390   392   394   396   398   399   400   401   402\n",
      "   405   408   409   411   416   420   421   425   426   428   430   431\n",
      "   435   440   442   445   449   450   454   457   459   460   475   476\n",
      "   485   487   489   490   500   504   505   507   508   510   514   515\n",
      "   517   519   520   521   525   530   540   541   544   550   551   553\n",
      "   560   572   574   579   580   584   585   599   600   601   602   603\n",
      "   604   606   607   610   612   620   640   645   650   651   671   678\n",
      "   682   685   696   700   702   703   732   743   750   751   754   771\n",
      "   776   800   805   808   850   851   871   900   901   902   903   907\n",
      "   909   923   950   952   953   960   998   999  1000  1001  1002  1003\n",
      "  1004  1005  1011  1012  1016  1017  1021  1024  1054  1055  1056  1062\n",
      "  1079  1082  1090  1100  1102  1103  1105  1111  1115  1120  1149  1151\n",
      "  1158  1160  1162  1164  1199  1200  1202  1221  1223  1230  1239  1240\n",
      "  1241  1250  1252  1256  1275  1288  1299  1300  1312  1317  1324  1339\n",
      "  1351  1360  1362  1363  1367  1390  1394  1398  1399  1400  1401  1403\n",
      "  1405  1416  1432  1433  1436  1500  1501  1502  1503  1506  1521  1548\n",
      "  1595  1596  1597  1598  1600  1625  1631  1653  1659  1689  1700  1701\n",
      "  1703  1704  1707  1753  1771  1779  1780  1781  1783  1793  1796  1799\n",
      "  1800  1801  1870  1895  1896  1900  1910  1920  1922  1933  1937  1968\n",
      "  1986  1988  1992  1993  1995  1998  1999  2000  2004  2005  2007  2009\n",
      "  2016  2017  2018  2172  2200  2201  2331  2340  2389  2402  2461  2598\n",
      "  2729  2789  2792  2799  3000  3199  3454  3500  3750  4400  4507  4700\n",
      "  5000  5411  5420  5575  5809  5815  5867  6006  6010  6011  6012  6018\n",
      "  6045  6062  6226  6512  6920  7508  7511  7512  7515  7518  7529  7544\n",
      "  8011  8259  8404  8500  9000  9007  9010  9011  9012  9013  9710 10000\n",
      " 10110 10218 10311 10317 10520 10522 10710 10910 10912 11011 11025 11111\n",
      " 11509 11530 11635 12012 12510 12512 12684 13616 13636 14009 15001 15016\n",
      " 15017 15020 15033 16011 16051 16311 16312 17011 17019 17410 17700 17932\n",
      " 19208 19211 19312 20000]\n",
      "\n",
      "Elementos de la columna mileage\n",
      "[  5000  10000  20000  30000  40000  50000  60000  70000  80000  90000\n",
      " 100000 125000 150000]\n",
      "\n",
      "Elementos de la columna registration_month\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Elementos de la columna number_of_pictures\n",
      "[0]\n",
      "\n",
      "Elementos de la columna postal_code\n",
      "[ 1067  1068  1069 ... 99994 99996 99998]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_prev(df):\n",
    "    fig, axes =plt.subplots(ncols=4,nrows=4,figsize=[12,12])\n",
    "\n",
    "    for ax, column in zip(axes.flatten(), df.columns):\n",
    "        ax.hist(df[column].dropna(), bins=10, color='g')\n",
    "        ax.grid(True)\n",
    "        ax.set_title(column)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_prev(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Observaciones\n",
    "\n",
    "\n",
    "Al momento nos encontramos con las siguientes situaciones:\n",
    "\n",
    "Elementos nulos para las columnas:\n",
    "- vehicle_type\n",
    "- gearbox \n",
    "- model\n",
    "- fuel_type\n",
    "- not_repaired\n",
    "\n",
    "A su vez, hemos identificado incongruencias en los datos registrados para las siguientes columnas: \n",
    "\n",
    "- `price`: En los valores de precio puedo observar valores de muy bajos que pueden ser considerados `sesgos de información.`\n",
    "- `registration year` : se pueden observar ver valores superiores al año actual y valores por debajo de 1886 (cuando se creó el primer vehículo), existen muchos `datos con sesgo`.\n",
    "- `power` la medición esta en caballos de vapor. El primer vehiculo creado tenía una fuerza de CV de 0.75, por lo que es incongruente ver valores de 0 en la base de datos, en su contraparte, el vehículo con mayor velocidad de CV regitrada para 2020 fue de 1800 CV, por lo que `tenemos incongruencias` en los datos cuyos valores superan los a 10,000 CV. \n",
    "\n",
    "De un total de 16 columnas, 8 columnas se encuentran sesgadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesgo de 'price'\n",
    "\n",
    "`- Existen precios de vehículos por debajo de los 600 dolares.`\n",
    "\n",
    "Para poder ejecutar un análisis mas profundo es necesario identificar que pudo haber pasado con los datos, una suposición sería que la base se descargo de una plataforma en línea donde los usuarios pueden decidir el precio final de su vehículo, algunos usuarios podrían optar por colocar precios irreales para llamar la atención de los compradores.\n",
    "\n",
    "Con el fin de alimentar nuestro modelo de una mejor manera, será necesario reclasificar o excluir los precios menores a 600 dolares. Este umbral se ha obtenido de la busqueda de los precios minimos y maximos para la venta de vehiculos en europa de los sitios\n",
    "- www.coches.com,\n",
    "- www.milanuncios.com\n",
    "\n",
    "Si realizaramos un filtro de precios encontrariamos 46,313 filas afectadas que representan el 13.07% del total del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesgo de 'registration_year'\n",
    "`- Se pueden observar ver valores superiores al año actual y valores por debajo de 1886 (antes del primer automovil creado).`\n",
    "\n",
    "Siguiendo las fuentes antes mencionadas, podemos ver vehículos ofertados con fecha de registro desde 1980, mantendremos este umbral en nuestro dataset, por otra parte el registro muestra vehiculos con fecha de registro mayor a 2016, fecha en la que se descargaron estos datos. Por lo que datos posteriores no deberían de considerarse para este estudio.\n",
    "\n",
    "Considerando la depuración del umbral mínimo y máximo, sería necesario depurar 17,978 filas representando un 5.07% del total del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesgo de 'power'\n",
    "`- Valores incongruentes en los CV, con valores inferiores a 60 y superiores a 500 en nuestra base de datos.`\n",
    "\n",
    "Para la seccion de power tenemos como entrada que el primer vehiculo construido tenía una potencia de Caballos de Vapor (CV) de 0.75. \n",
    "De acuerdo con las paginas antes mencionadas, los vehiculos pueden tener una potencia entre 60 y 400 cv\n",
    "\n",
    "\n",
    "Se obtuvieron muestras al azar los vehiculos de la base de datos con registro mayor a 400cv y ningúno clasifico con mas de 250 cv reales, por lo que limitaremos la búsqueda a 300 cv\n",
    "Si manejamos los umbrales de 60,300 tendríamos un total de 67,268  datos por de purar representando un 18.99% del dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sesgo de 'mileage'\n",
    "`- Existen vehiculos con registro de salida del año en curso y con 150,000 km registrados (datos incongruentes).`\n",
    "\n",
    "En promedio, los vehiculos generarn un kilometraje de 15,000 a 27,000 kms por año, para minimizar los datos afectados, se excluiran los autos con un kilometraje mayor a 150,000 para añós posteriores a 2011. (27 kms por añó).\n",
    "19102 filas que corresponden a un 5.39 del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera conclusión\n",
    "\n",
    "El dataset descargado presenta bastantes datos sesgados e incongruentes, si bien hemos establecido la hipótesis de que la base se descargo de una plataforma en línea donde los usuarios pueden decidir el precio final de su vehículo no podemos asegurar que sea correcta, sin embargo el enfoque principal del de este proyecto se basa en entrenar un modelo de predicción, por lo que será necesario excluir estos datos para tener una base de mejor calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluyendo valores price\n",
    "recalibrate_df= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalibrate_df= recalibrate_df.query('price>=600')\n",
    "recalibrate_df = recalibrate_df.query(' 1980 < registration_year < 2017')\n",
    "recalibrate_df = recalibrate_df.query('60 <=power <=300')\n",
    "recalibrate_df = recalibrate_df.query('~(registration_year>=2012 and mileage >= 150000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha depurado un 30.42 de la data original\n"
     ]
    }
   ],
   "source": [
    "loss_data = (1 - (recalibrate_df.shape[0] / df.shape[0])) *100\n",
    "print(f'Se ha depurado un {loss_data:.2f} de la data original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_repaired          30254\n",
       "fuel_type              9408\n",
       "model                  7475\n",
       "vehicle_type           3932\n",
       "gearbox                3357\n",
       "date_crawled              0\n",
       "price                     0\n",
       "registration_year         0\n",
       "power                     0\n",
       "mileage                   0\n",
       "registration_month        0\n",
       "brand                     0\n",
       "date_created              0\n",
       "number_of_pictures        0\n",
       "postal_code               0\n",
       "last_seen                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalibrate_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_prev(recalibrate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas de power y de registration year ahora tienen coherencia, el kilometraje sigue estando alto para autos con valores de recorrido mayor a 150,000, de acuerdo con la información externa, esta puede entrar en el umbral de 27,000 kms por año."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nuloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la manipulación de los valores nulos, se han analizado las siguientes opciones:\n",
    "- Eliminación de filas o columnas con valores nulos\n",
    "- Imputación de valores nulos\n",
    "`- Uso de modelos de imputación`\n",
    "- Codificación de valores nulos\n",
    "\n",
    "Optaré por el uso de modelos de imputación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputated_df = recalibrate_df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mantenemos las columnas que realmente nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputated_df = imputated_df.drop(columns=['date_crawled','date_created','number_of_pictures', 'last_seen','postal_code'])\n",
    "\n",
    "# chart_prev(imputated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255804</th>\n",
       "      <td>8900</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2007</td>\n",
       "      <td>manual</td>\n",
       "      <td>170</td>\n",
       "      <td>passat</td>\n",
       "      <td>150000</td>\n",
       "      <td>2</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203174</th>\n",
       "      <td>8000</td>\n",
       "      <td>bus</td>\n",
       "      <td>2006</td>\n",
       "      <td>manual</td>\n",
       "      <td>116</td>\n",
       "      <td>sharan</td>\n",
       "      <td>150000</td>\n",
       "      <td>11</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>7300</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2002</td>\n",
       "      <td>auto</td>\n",
       "      <td>150</td>\n",
       "      <td>a4</td>\n",
       "      <td>125000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>audi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161753</th>\n",
       "      <td>11900</td>\n",
       "      <td>convertible</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>slk</td>\n",
       "      <td>70000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107968</th>\n",
       "      <td>9990</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>109</td>\n",
       "      <td>clubman</td>\n",
       "      <td>125000</td>\n",
       "      <td>1</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>mini</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price vehicle_type  registration_year gearbox  power    model  \\\n",
       "255804   8900        wagon               2007  manual    170   passat   \n",
       "203174   8000          bus               2006  manual    116   sharan   \n",
       "6927     7300        sedan               2002    auto    150       a4   \n",
       "161753  11900  convertible               2004    auto    163      slk   \n",
       "107968   9990        wagon               2008  manual    109  clubman   \n",
       "\n",
       "        mileage  registration_month fuel_type          brand not_repaired  \n",
       "255804   150000                   2  gasoline     volkswagen            0  \n",
       "203174   150000                  11  gasoline     volkswagen            0  \n",
       "6927     125000                   6    petrol           audi            0  \n",
       "161753    70000                   3    petrol  mercedes_benz            0  \n",
       "107968   125000                   1  gasoline           mini            0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputated_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE(df):\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded_data = encoder.fit_transform(df)\n",
    "    output_names = encoder.get_feature_names_out(df.columns)\n",
    "    df_codified = pd.DataFrame(encoded_data.toarray(), columns=output_names, index= df.index)\n",
    "    return df_codified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scaler(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_date = scaler.fit_transform(df)\n",
    "    return scaled_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarizando valores numéricos para mejorar los resultados de el modelo LinerarRegression, los modelos RandomForest y LightGBM no se verán beneficiados ni perjudicados por esta manipulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarized_df = imputated_df.drop(columns=['price'])\n",
    "# int_colums = standarized_df.select_dtypes(include=[int]).columns\n",
    "# standarized_df[int_colums] = Scaler(standarized_df[int_colums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarized_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_cols = standarized_df.select_dtypes(include=['object']).columns\n",
    "# new_cols = OHE(standarized_df[obj_cols])\n",
    "\n",
    "# standarized_df =standarized_df.drop(columns=obj_cols)\n",
    "# standarized_df = pd.concat([standarized_df, new_cols], axis=1)\n",
    "\n",
    "obj_cols = imputated_df.select_dtypes(include=['object']).columns\n",
    "new_cols = OHE(imputated_df[obj_cols])\n",
    "\n",
    "imputated_df =imputated_df.drop(columns=obj_cols)\n",
    "imputated_df = pd.concat([imputated_df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = standarized_df\n",
    "# y = imputated_df['price']\n",
    "\n",
    "\n",
    "X = imputated_df\n",
    "y = imputated_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>power</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>vehicle_type_bus</th>\n",
       "      <th>vehicle_type_convertible</th>\n",
       "      <th>vehicle_type_coupe</th>\n",
       "      <th>vehicle_type_other</th>\n",
       "      <th>vehicle_type_sedan</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_seat</th>\n",
       "      <th>brand_skoda</th>\n",
       "      <th>brand_smart</th>\n",
       "      <th>brand_subaru</th>\n",
       "      <th>brand_suzuki</th>\n",
       "      <th>brand_toyota</th>\n",
       "      <th>brand_volkswagen</th>\n",
       "      <th>brand_volvo</th>\n",
       "      <th>not_repaired_0</th>\n",
       "      <th>not_repaired_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>2001</td>\n",
       "      <td>75</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>2008</td>\n",
       "      <td>69</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>650</td>\n",
       "      <td>1995</td>\n",
       "      <td>102</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2200</td>\n",
       "      <td>2004</td>\n",
       "      <td>109</td>\n",
       "      <td>150000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2000</td>\n",
       "      <td>2004</td>\n",
       "      <td>105</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354093</th>\n",
       "      <td>4400</td>\n",
       "      <td>2008</td>\n",
       "      <td>105</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354097</th>\n",
       "      <td>7900</td>\n",
       "      <td>2010</td>\n",
       "      <td>140</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354100</th>\n",
       "      <td>3200</td>\n",
       "      <td>2004</td>\n",
       "      <td>225</td>\n",
       "      <td>150000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354104</th>\n",
       "      <td>1199</td>\n",
       "      <td>2000</td>\n",
       "      <td>101</td>\n",
       "      <td>125000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354105</th>\n",
       "      <td>9200</td>\n",
       "      <td>1996</td>\n",
       "      <td>102</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203454 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  registration_year  power  mileage  registration_month  \\\n",
       "3        1500               2001     75   150000                   6   \n",
       "4        3600               2008     69    90000                   7   \n",
       "5         650               1995    102   150000                  10   \n",
       "6        2200               2004    109   150000                   8   \n",
       "10       2000               2004    105   150000                  12   \n",
       "...       ...                ...    ...      ...                 ...   \n",
       "354093   4400               2008    105   150000                   7   \n",
       "354097   7900               2010    140   150000                   7   \n",
       "354100   3200               2004    225   150000                   5   \n",
       "354104   1199               2000    101   125000                   3   \n",
       "354105   9200               1996    102   150000                   3   \n",
       "\n",
       "        vehicle_type_bus  vehicle_type_convertible  vehicle_type_coupe  \\\n",
       "3                    0.0                       0.0                 0.0   \n",
       "4                    0.0                       0.0                 0.0   \n",
       "5                    0.0                       0.0                 0.0   \n",
       "6                    0.0                       1.0                 0.0   \n",
       "10                   0.0                       0.0                 0.0   \n",
       "...                  ...                       ...                 ...   \n",
       "354093               0.0                       0.0                 0.0   \n",
       "354097               0.0                       0.0                 0.0   \n",
       "354100               0.0                       0.0                 0.0   \n",
       "354104               0.0                       1.0                 0.0   \n",
       "354105               1.0                       0.0                 0.0   \n",
       "\n",
       "        vehicle_type_other  vehicle_type_sedan  ...  brand_seat  brand_skoda  \\\n",
       "3                      0.0                 0.0  ...         0.0          0.0   \n",
       "4                      0.0                 0.0  ...         0.0          1.0   \n",
       "5                      0.0                 1.0  ...         0.0          0.0   \n",
       "6                      0.0                 0.0  ...         0.0          0.0   \n",
       "10                     0.0                 1.0  ...         0.0          0.0   \n",
       "...                    ...                 ...  ...         ...          ...   \n",
       "354093                 0.0                 1.0  ...         1.0          0.0   \n",
       "354097                 0.0                 1.0  ...         0.0          0.0   \n",
       "354100                 0.0                 1.0  ...         1.0          0.0   \n",
       "354104                 0.0                 0.0  ...         0.0          0.0   \n",
       "354105                 0.0                 0.0  ...         0.0          0.0   \n",
       "\n",
       "        brand_smart  brand_subaru  brand_suzuki  brand_toyota  \\\n",
       "3               0.0           0.0           0.0           0.0   \n",
       "4               0.0           0.0           0.0           0.0   \n",
       "5               0.0           0.0           0.0           0.0   \n",
       "6               0.0           0.0           0.0           0.0   \n",
       "10              0.0           0.0           0.0           0.0   \n",
       "...             ...           ...           ...           ...   \n",
       "354093          0.0           0.0           0.0           0.0   \n",
       "354097          0.0           0.0           0.0           0.0   \n",
       "354100          0.0           0.0           0.0           0.0   \n",
       "354104          1.0           0.0           0.0           0.0   \n",
       "354105          0.0           0.0           0.0           0.0   \n",
       "\n",
       "        brand_volkswagen  brand_volvo  not_repaired_0  not_repaired_1  \n",
       "3                    1.0          0.0             1.0             0.0  \n",
       "4                    0.0          0.0             1.0             0.0  \n",
       "5                    0.0          0.0             0.0             1.0  \n",
       "6                    0.0          0.0             1.0             0.0  \n",
       "10                   0.0          0.0             1.0             0.0  \n",
       "...                  ...          ...             ...             ...  \n",
       "354093               0.0          0.0             1.0             0.0  \n",
       "354097               1.0          0.0             1.0             0.0  \n",
       "354100               0.0          0.0             0.0             1.0  \n",
       "354104               0.0          0.0             1.0             0.0  \n",
       "354105               1.0          0.0             1.0             0.0  \n",
       "\n",
       "[203454 rows x 309 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X,y, model, params):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=100) \n",
    "\n",
    "    grid_search = GridSearchCV(model, params, scoring='neg_mean_squared_error', cv=5, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    rmse = root_mean_squared_error(y_test,y_pred)\n",
    "\n",
    "\n",
    "    return grid_search, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .................................fit_intercept=True; total time=   5.1s\n",
      "[CV] END .................................fit_intercept=True; total time=   4.1s\n",
      "[CV] END .................................fit_intercept=True; total time=   4.2s\n",
      "[CV] END .................................fit_intercept=True; total time=   4.2s\n",
      "[CV] END .................................fit_intercept=True; total time=   4.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   4.1s\n",
      "[CV] END ................................fit_intercept=False; total time=   5.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   4.2s\n",
      "[CV] END ................................fit_intercept=False; total time=   4.2s\n",
      "[CV] END ................................fit_intercept=False; total time=   4.1s\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "params = {\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "grid_search, rmse = model_training(X,y,model,params)\n",
    "\n",
    "# print(\"RMSE:\", rmse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.2718501462409623e-11\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.307136</td>\n",
       "      <td>0.409045</td>\n",
       "      <td>0.110845</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>True</td>\n",
       "      <td>{'fit_intercept': True}</td>\n",
       "      <td>-1.432255e-21</td>\n",
       "      <td>-9.240535e-23</td>\n",
       "      <td>-7.264991e-22</td>\n",
       "      <td>-1.175666e-20</td>\n",
       "      <td>-1.222863e-21</td>\n",
       "      <td>-3.046137e-21</td>\n",
       "      <td>4.379667e-21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.286282</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>0.107592</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>False</td>\n",
       "      <td>{'fit_intercept': False}</td>\n",
       "      <td>-1.051156e-20</td>\n",
       "      <td>-8.770121e-21</td>\n",
       "      <td>-1.135886e-20</td>\n",
       "      <td>-9.583182e-21</td>\n",
       "      <td>-1.101300e-20</td>\n",
       "      <td>-1.024734e-20</td>\n",
       "      <td>9.502427e-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.307136      0.409045         0.110845        0.005775   \n",
       "1       4.286282      0.340223         0.107592        0.004134   \n",
       "\n",
       "  param_fit_intercept                    params  split0_test_score  \\\n",
       "0                True   {'fit_intercept': True}      -1.432255e-21   \n",
       "1               False  {'fit_intercept': False}      -1.051156e-20   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0      -9.240535e-23      -7.264991e-22      -1.175666e-20      -1.222863e-21   \n",
       "1      -8.770121e-21      -1.135886e-20      -9.583182e-21      -1.101300e-20   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0    -3.046137e-21    4.379667e-21                1  \n",
       "1    -1.024734e-20    9.502427e-22                2  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= imputated_df['price']\n",
    "model = LGBMRegressor()\n",
    "params = {\n",
    "    'boosting_type': ['gbdt','dart'],\n",
    "    'num_leaves': [20,30,40],\n",
    "    'learning_rate': [0.05,0.1,0.2],\n",
    "    'n_estimators': [50,100,200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 495\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 491\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 496\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1012\n",
      "[LightGBM] [Info] Number of data points in the train set: 152590, number of used features: 506\n",
      "[LightGBM] [Info] Start training from score 5687.942250\n"
     ]
    }
   ],
   "source": [
    "rmse_lgbm = model_training(X,y,model,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1590.4910096686092\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", rmse_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=100)\n",
    "params = {\n",
    "    'n_estimators': [50,10,100],\n",
    "    'max_depth': [None,10,20],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf': [1,2,4]\n",
    "}\n",
    "\n",
    "rmse_rf = model_training(X,y,model,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 18775602690846.797\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'max{y.max()}, min{y.min()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe 'x' para verificar. Luego presiona Shift+Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook está abierto\n",
    "- [ ]  El código no tiene errores- [ ]  Las celdas con el código han sido colocadas en orden de ejecución- [ ]  Los datos han sido descargados y preparados- [ ]  Los modelos han sido entrenados\n",
    "- [ ]  Se realizó el análisis de velocidad y calidad de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
