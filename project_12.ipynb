{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from math import sqrt\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U --user scikit-learn\n",
    "# %pip install -U --user lightgbm\n",
    "# %pip install -U --user catboost\n",
    "# %pip install -U --user xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importacion del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/Tripleten/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización general del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339028</th>\n",
       "      <td>26/03/2016 18:06</td>\n",
       "      <td>9000</td>\n",
       "      <td>small</td>\n",
       "      <td>2012</td>\n",
       "      <td>manual</td>\n",
       "      <td>101</td>\n",
       "      <td>corsa</td>\n",
       "      <td>60000</td>\n",
       "      <td>12</td>\n",
       "      <td>petrol</td>\n",
       "      <td>opel</td>\n",
       "      <td>no</td>\n",
       "      <td>26/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 18:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302404</th>\n",
       "      <td>30/03/2016 22:54</td>\n",
       "      <td>9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>transporter</td>\n",
       "      <td>5000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>42107</td>\n",
       "      <td>05/04/2016 19:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233579</th>\n",
       "      <td>28/03/2016 22:36</td>\n",
       "      <td>18000</td>\n",
       "      <td>coupe</td>\n",
       "      <td>1985</td>\n",
       "      <td>auto</td>\n",
       "      <td>125</td>\n",
       "      <td>other</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>no</td>\n",
       "      <td>28/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>76571</td>\n",
       "      <td>05/04/2016 12:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233104</th>\n",
       "      <td>01/04/2016 21:46</td>\n",
       "      <td>2780</td>\n",
       "      <td>convertible</td>\n",
       "      <td>1996</td>\n",
       "      <td>manual</td>\n",
       "      <td>90</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>lpg</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>01/04/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>49716</td>\n",
       "      <td>05/04/2016 19:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateCrawled  Price  VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "339028  26/03/2016 18:06   9000        small              2012  manual    101   \n",
       "302404  30/03/2016 22:54   9000          NaN              2017     NaN      0   \n",
       "233579  28/03/2016 22:36  18000        coupe              1985    auto    125   \n",
       "233104  01/04/2016 21:46   2780  convertible              1996  manual     90   \n",
       "\n",
       "              Model  Mileage  RegistrationMonth  FuelType          Brand  \\\n",
       "339028        corsa    60000                 12    petrol           opel   \n",
       "302404  transporter     5000                  7  gasoline     volkswagen   \n",
       "233579        other   150000                  7  gasoline  mercedes_benz   \n",
       "233104         golf   150000                  3       lpg     volkswagen   \n",
       "\n",
       "       NotRepaired       DateCreated  NumberOfPictures  PostalCode  \\\n",
       "339028          no  26/03/2016 00:00                 0       60437   \n",
       "302404         NaN  30/03/2016 00:00                 0       42107   \n",
       "233579          no  28/03/2016 00:00                 0       76571   \n",
       "233104          no  01/04/2016 00:00                 0       49716   \n",
       "\n",
       "                LastSeen  \n",
       "339028  06/04/2016 18:19  \n",
       "302404  05/04/2016 19:15  \n",
       "233579  05/04/2016 12:45  \n",
       "233104  05/04/2016 19:44  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto se basará en la predicción del precio por lo que prepararemos los datos para un  modelo de regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se renombran las columnas para mantener formato snake_case en el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "snake_case_cols = []\n",
    "\n",
    "for col in cols:\n",
    "    snake_case_col = '_'.join(re.findall(r'[A-Z][a-z0-9]*', col)).lower()\n",
    "    snake_case_cols.append(snake_case_col)\n",
    "\n",
    "# print(snake_case_cols)\n",
    "df.columns = snake_case_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obteniendo información general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215721</th>\n",
       "      <td>18/03/2016 12:47</td>\n",
       "      <td>1399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>manual</td>\n",
       "      <td>90</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>95460</td>\n",
       "      <td>29/03/2016 12:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49175</th>\n",
       "      <td>12/03/2016 07:58</td>\n",
       "      <td>5900</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2007</td>\n",
       "      <td>manual</td>\n",
       "      <td>105</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>9</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>12/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>92318</td>\n",
       "      <td>12/03/2016 09:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325158</th>\n",
       "      <td>19/03/2016 23:52</td>\n",
       "      <td>4800</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2003</td>\n",
       "      <td>auto</td>\n",
       "      <td>170</td>\n",
       "      <td>c_klasse</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>mercedes_benz</td>\n",
       "      <td>no</td>\n",
       "      <td>19/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>22049</td>\n",
       "      <td>20/03/2016 07:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126513</th>\n",
       "      <td>30/03/2016 23:52</td>\n",
       "      <td>16500</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2005</td>\n",
       "      <td>auto</td>\n",
       "      <td>334</td>\n",
       "      <td>a8</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>audi</td>\n",
       "      <td>no</td>\n",
       "      <td>30/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>84028</td>\n",
       "      <td>06/04/2016 00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215077</th>\n",
       "      <td>16/03/2016 09:51</td>\n",
       "      <td>3600</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2006</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>focus</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>ford</td>\n",
       "      <td>no</td>\n",
       "      <td>16/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>44339</td>\n",
       "      <td>06/04/2016 02:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_crawled  price vehicle_type  registration_year gearbox  \\\n",
       "215721  18/03/2016 12:47   1399          NaN               2018  manual   \n",
       "49175   12/03/2016 07:58   5900        sedan               2007  manual   \n",
       "325158  19/03/2016 23:52   4800        wagon               2003    auto   \n",
       "126513  30/03/2016 23:52  16500        sedan               2005    auto   \n",
       "215077  16/03/2016 09:51   3600        wagon               2006  manual   \n",
       "\n",
       "        power     model  mileage  registration_month fuel_type          brand  \\\n",
       "215721     90      golf   150000                   1       NaN     volkswagen   \n",
       "49175     105      golf   150000                   9  gasoline     volkswagen   \n",
       "325158    170  c_klasse   150000                   7  gasoline  mercedes_benz   \n",
       "126513    334        a8   150000                   6    petrol           audi   \n",
       "215077      0     focus   150000                   6  gasoline           ford   \n",
       "\n",
       "       not_repaired      date_created  number_of_pictures  postal_code  \\\n",
       "215721          NaN  18/03/2016 00:00                   0        95460   \n",
       "49175            no  12/03/2016 00:00                   0        92318   \n",
       "325158           no  19/03/2016 00:00                   0        22049   \n",
       "126513           no  30/03/2016 00:00                   0        84028   \n",
       "215077           no  16/03/2016 00:00                   0        44339   \n",
       "\n",
       "               last_seen  \n",
       "215721  29/03/2016 12:49  \n",
       "49175   12/03/2016 09:43  \n",
       "325158  20/03/2016 07:40  \n",
       "126513  06/04/2016 00:17  \n",
       "215077  06/04/2016 02:44  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando la estructura del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   date_crawled        354369 non-null  object\n",
      " 1   price               354369 non-null  int64 \n",
      " 2   vehicle_type        316879 non-null  object\n",
      " 3   registration_year   354369 non-null  int64 \n",
      " 4   gearbox             334536 non-null  object\n",
      " 5   power               354369 non-null  int64 \n",
      " 6   model               334664 non-null  object\n",
      " 7   mileage             354369 non-null  int64 \n",
      " 8   registration_month  354369 non-null  int64 \n",
      " 9   fuel_type           321474 non-null  object\n",
      " 10  brand               354369 non-null  object\n",
      " 11  not_repaired        283215 non-null  object\n",
      " 12  date_created        354369 non-null  object\n",
      " 13  number_of_pictures  354369 non-null  int64 \n",
      " 14  postal_code         354369 non-null  int64 \n",
      " 15  last_seen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificando columnas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values by column:\n",
      "vehicle_type    37490\n",
      "gearbox         19833\n",
      "model           19705\n",
      "fuel_type       32895\n",
      "not_repaired    71154\n",
      "dtype: int64\n",
      "\n",
      "Total null rows: 108555\n"
     ]
    }
   ],
   "source": [
    "null_values = df.isna().sum()\n",
    "null_rows= df.shape[0] - df.dropna().shape[0]\n",
    "\n",
    "null_values = null_values[null_values>0]\n",
    "\n",
    "\n",
    "print(f'Null values by column:')\n",
    "print(null_values, end='\\n\\n')\n",
    "print(f'Total null rows: {null_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificacndo valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_rows = df.duplicated()\n",
    "duplicated_rows.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinando manualmente un caso para verificar coherencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>21/03/2016 19:06</td>\n",
       "      <td>5999</td>\n",
       "      <td>small</td>\n",
       "      <td>2009</td>\n",
       "      <td>manual</td>\n",
       "      <td>80</td>\n",
       "      <td>polo</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>21/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65529</td>\n",
       "      <td>05/04/2016 20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14266</th>\n",
       "      <td>21/03/2016 19:06</td>\n",
       "      <td>5999</td>\n",
       "      <td>small</td>\n",
       "      <td>2009</td>\n",
       "      <td>manual</td>\n",
       "      <td>80</td>\n",
       "      <td>polo</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>21/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>65529</td>\n",
       "      <td>05/04/2016 20:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_crawled  price vehicle_type  registration_year gearbox  power  \\\n",
       "183    21/03/2016 19:06   5999        small               2009  manual     80   \n",
       "14266  21/03/2016 19:06   5999        small               2009  manual     80   \n",
       "\n",
       "      model  mileage  registration_month fuel_type       brand not_repaired  \\\n",
       "183    polo   125000                   5    petrol  volkswagen           no   \n",
       "14266  polo   125000                   5    petrol  volkswagen           no   \n",
       "\n",
       "           date_created  number_of_pictures  postal_code         last_seen  \n",
       "183    21/03/2016 00:00                   0        65529  05/04/2016 20:47  \n",
       "14266  21/03/2016 00:00                   0        65529  05/04/2016 20:47  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['date_crawled'] == '21/03/2016 19:06') & (df['price']== 5999)]\n",
    "# df.query(\"date_crawled == '21/03/2016 19:06' and price == 5999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "\n",
    "- Elementos con clasificaciones Dtype erroneos (price, not_repaired, date_crawled, last_seen)\n",
    "- Elementos nulos para las columnas (vehicle_type, gearbox, model, fuel_type, not_repaired)\n",
    "- 262 elementos duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificamos la columna 'not_repaired' a booleano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm_he\\AppData\\Local\\Temp\\ipykernel_5844\\2022677092.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['not_repaired']= df['not_repaired'].replace({'yes':1, 'no':0})\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('future.no_silent_downcasting', True)\n",
    "df['not_repaired']= df['not_repaired'].replace({'yes':1, 'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reasignaran los tipos de valor 'date_crawled' y 'last_seen' al formato 'datetime64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_crawled'] = pd.to_datetime(df['date_crawled'], format='%d/%m/%Y %H:%M')\n",
    "df['last_seen'] = pd.to_datetime(df['last_seen'], format='%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando cambios realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "print(df['date_crawled'].dt.year.unique() == df['last_seen'].dt.year.unique())\n",
    "# print(df['date_crawled'].dt.month.sort_values().unique() == df['last_seen'].dt.month.sort_values().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a eliminar los valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una función que permita analizar visualmente los elementos únicos que se encuentran dentro de las columnas (para verificar datos incongruentes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(db):\n",
    "    obj = db.select_dtypes(include='object').columns\n",
    "    int = db.select_dtypes(include='int').columns\n",
    "    \n",
    "    print('Analisis de elementos Object')\n",
    "    for i in obj:\n",
    "\n",
    "        print(f'Elementos de la columna {i}')\n",
    "        print(db[i].sort_values().unique(), end='\\n\\n')\n",
    "\n",
    "    for i in int:\n",
    "\n",
    "        print(f'Elementos de la columna {i}')\n",
    "        print(db[i].sort_values().unique(), end='\\n\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisis de elementos Object\n",
      "Elementos de la columna vehicle_type\n",
      "['bus' 'convertible' 'coupe' 'other' 'sedan' 'small' 'suv' 'wagon' nan]\n",
      "\n",
      "Elementos de la columna gearbox\n",
      "['auto' 'manual' nan]\n",
      "\n",
      "Elementos de la columna model\n",
      "['100' '145' '147' '156' '159' '1_reihe' '1er' '200' '2_reihe' '300c'\n",
      " '3_reihe' '3er' '4_reihe' '500' '5_reihe' '5er' '601' '6_reihe' '6er'\n",
      " '7er' '80' '850' '90' '900' '9000' '911' 'a1' 'a2' 'a3' 'a4' 'a5' 'a6'\n",
      " 'a8' 'a_klasse' 'accord' 'agila' 'alhambra' 'almera' 'altea' 'amarok'\n",
      " 'antara' 'arosa' 'astra' 'auris' 'avensis' 'aveo' 'aygo' 'b_klasse'\n",
      " 'b_max' 'beetle' 'berlingo' 'bora' 'boxster' 'bravo' 'c1' 'c2' 'c3' 'c4'\n",
      " 'c5' 'c_klasse' 'c_max' 'c_reihe' 'caddy' 'calibra' 'captiva' 'carisma'\n",
      " 'carnival' 'cayenne' 'cc' 'ceed' 'charade' 'cherokee' 'citigo' 'civic'\n",
      " 'cl' 'clio' 'clk' 'clubman' 'colt' 'combo' 'cooper' 'cordoba' 'corolla'\n",
      " 'corsa' 'cr_reihe' 'croma' 'crossfire' 'cuore' 'cx_reihe' 'defender'\n",
      " 'delta' 'discovery' 'doblo' 'ducato' 'duster' 'e_klasse' 'elefantino'\n",
      " 'eos' 'escort' 'espace' 'exeo' 'fabia' 'fiesta' 'focus' 'forester'\n",
      " 'forfour' 'fortwo' 'fox' 'freelander' 'fusion' 'g_klasse' 'galant'\n",
      " 'galaxy' 'getz' 'gl' 'glk' 'golf' 'grand' 'i3' 'i_reihe' 'ibiza'\n",
      " 'impreza' 'insignia' 'jazz' 'jetta' 'jimny' 'juke' 'justy' 'ka' 'kadett'\n",
      " 'kaefer' 'kalina' 'kalos' 'kangoo' 'kappa' 'kuga' 'laguna' 'lancer'\n",
      " 'lanos' 'legacy' 'leon' 'lodgy' 'logan' 'lupo' 'lybra' 'm_klasse'\n",
      " 'm_reihe' 'materia' 'matiz' 'megane' 'meriva' 'micra' 'mii' 'modus'\n",
      " 'mondeo' 'move' 'musa' 'mustang' 'mx_reihe' 'navara' 'niva' 'note'\n",
      " 'nubira' 'octavia' 'omega' 'one' 'other' 'outlander' 'pajero' 'panda'\n",
      " 'passat' 'phaeton' 'picanto' 'polo' 'primera' 'ptcruiser' 'punto' 'q3'\n",
      " 'q5' 'q7' 'qashqai' 'r19' 'range_rover' 'range_rover_evoque'\n",
      " 'range_rover_sport' 'rangerover' 'rav' 'rio' 'roadster' 'roomster'\n",
      " 'rx_reihe' 's60' 's_klasse' 's_max' 's_type' 'samara' 'sandero' 'santa'\n",
      " 'scenic' 'scirocco' 'seicento' 'serie_1' 'serie_2' 'serie_3' 'sharan'\n",
      " 'signum' 'sirion' 'sl' 'slk' 'sorento' 'spark' 'spider' 'sportage'\n",
      " 'sprinter' 'stilo' 'superb' 'swift' 'terios' 'tigra' 'tiguan' 'toledo'\n",
      " 'touareg' 'touran' 'transit' 'transporter' 'tt' 'tucson' 'twingo' 'up'\n",
      " 'v40' 'v50' 'v60' 'v70' 'v_klasse' 'vectra' 'verso' 'viano' 'vito'\n",
      " 'vivaro' 'voyager' 'wrangler' 'x_reihe' 'x_trail' 'x_type' 'xc_reihe'\n",
      " 'yaris' 'yeti' 'ypsilon' 'z_reihe' 'zafira' nan]\n",
      "\n",
      "Elementos de la columna fuel_type\n",
      "['cng' 'electric' 'gasoline' 'hybrid' 'lpg' 'other' 'petrol' nan]\n",
      "\n",
      "Elementos de la columna brand\n",
      "['alfa_romeo' 'audi' 'bmw' 'chevrolet' 'chrysler' 'citroen' 'dacia'\n",
      " 'daewoo' 'daihatsu' 'fiat' 'ford' 'honda' 'hyundai' 'jaguar' 'jeep' 'kia'\n",
      " 'lada' 'lancia' 'land_rover' 'mazda' 'mercedes_benz' 'mini' 'mitsubishi'\n",
      " 'nissan' 'opel' 'peugeot' 'porsche' 'renault' 'rover' 'saab' 'seat'\n",
      " 'skoda' 'smart' 'sonstige_autos' 'subaru' 'suzuki' 'toyota' 'trabant'\n",
      " 'volkswagen' 'volvo']\n",
      "\n",
      "Elementos de la columna date_created\n",
      "['01/02/2016 00:00' '01/03/2016 00:00' '01/04/2016 00:00'\n",
      " '02/01/2016 00:00' '02/02/2016 00:00' '02/03/2016 00:00'\n",
      " '02/04/2016 00:00' '02/11/2015 00:00' '03/01/2016 00:00'\n",
      " '03/02/2016 00:00' '03/03/2016 00:00' '03/04/2016 00:00'\n",
      " '04/02/2016 00:00' '04/03/2016 00:00' '04/04/2016 00:00'\n",
      " '04/09/2015 00:00' '05/02/2016 00:00' '05/03/2016 00:00'\n",
      " '05/04/2016 00:00' '05/12/2015 00:00' '06/01/2016 00:00'\n",
      " '06/02/2016 00:00' '06/03/2016 00:00' '06/04/2016 00:00'\n",
      " '06/12/2015 00:00' '07/01/2016 00:00' '07/02/2016 00:00'\n",
      " '07/03/2016 00:00' '07/04/2016 00:00' '07/08/2015 00:00'\n",
      " '08/01/2016 00:00' '08/02/2016 00:00' '08/03/2016 00:00'\n",
      " '08/11/2015 00:00' '09/02/2016 00:00' '09/03/2016 00:00'\n",
      " '09/09/2015 00:00' '10/01/2016 00:00' '10/02/2016 00:00'\n",
      " '10/03/2014 00:00' '10/03/2016 00:00' '10/08/2015 00:00'\n",
      " '10/11/2015 00:00' '11/02/2016 00:00' '11/03/2016 00:00'\n",
      " '12/02/2016 00:00' '12/03/2016 00:00' '12/11/2015 00:00'\n",
      " '13/01/2016 00:00' '13/02/2016 00:00' '13/03/2016 00:00'\n",
      " '14/02/2016 00:00' '14/03/2016 00:00' '15/01/2016 00:00'\n",
      " '15/02/2016 00:00' '15/03/2016 00:00' '16/01/2016 00:00'\n",
      " '16/02/2016 00:00' '16/03/2016 00:00' '17/01/2016 00:00'\n",
      " '17/02/2016 00:00' '17/03/2016 00:00' '17/11/2015 00:00'\n",
      " '17/12/2015 00:00' '18/01/2016 00:00' '18/02/2016 00:00'\n",
      " '18/03/2016 00:00' '18/06/2015 00:00' '19/01/2016 00:00'\n",
      " '19/02/2016 00:00' '19/03/2016 00:00' '20/01/2016 00:00'\n",
      " '20/02/2016 00:00' '20/03/2015 00:00' '20/03/2016 00:00'\n",
      " '21/02/2016 00:00' '21/03/2016 00:00' '22/01/2016 00:00'\n",
      " '22/02/2016 00:00' '22/03/2016 00:00' '23/01/2016 00:00'\n",
      " '23/02/2016 00:00' '23/03/2016 00:00' '23/11/2015 00:00'\n",
      " '24/01/2016 00:00' '24/02/2016 00:00' '24/03/2016 00:00'\n",
      " '24/11/2015 00:00' '25/01/2016 00:00' '25/02/2016 00:00'\n",
      " '25/03/2016 00:00' '26/01/2016 00:00' '26/02/2016 00:00'\n",
      " '26/03/2016 00:00' '27/01/2016 00:00' '27/02/2016 00:00'\n",
      " '27/03/2016 00:00' '27/12/2015 00:00' '28/01/2016 00:00'\n",
      " '28/02/2016 00:00' '28/03/2016 00:00' '29/01/2016 00:00'\n",
      " '29/02/2016 00:00' '29/03/2016 00:00' '30/01/2016 00:00'\n",
      " '30/03/2016 00:00' '30/12/2015 00:00' '31/01/2016 00:00'\n",
      " '31/03/2016 00:00']\n",
      "\n",
      "Elementos de la columna price\n",
      "[    0     1     2 ... 19998 19999 20000]\n",
      "\n",
      "Elementos de la columna registration_year\n",
      "[1000 1001 1039 1111 1200 1234 1253 1255 1300 1400 1500 1600 1602 1688\n",
      " 1800 1910 1915 1919 1920 1923 1925 1927 1928 1929 1930 1931 1932 1933\n",
      " 1934 1935 1936 1937 1938 1940 1941 1942 1943 1944 1945 1946 1947 1948\n",
      " 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962\n",
      " 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976\n",
      " 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990\n",
      " 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004\n",
      " 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018\n",
      " 2019 2066 2200 2222 2290 2500 2800 2900 3000 3200 3500 3700 3800 4000\n",
      " 4100 4500 4800 5000 5300 5555 5600 5900 5911 6000 6500 7000 7100 7500\n",
      " 7800 8000 8200 8455 8500 8888 9000 9229 9450 9996 9999]\n",
      "\n",
      "Elementos de la columna power\n",
      "[    0     1     2     3     4     5     6     7     8     9    10    11\n",
      "    12    13    14    15    16    17    18    19    20    21    22    23\n",
      "    24    25    26    27    28    29    30    31    32    33    34    35\n",
      "    36    37    38    39    40    41    42    43    44    45    46    47\n",
      "    48    49    50    51    52    53    54    55    56    57    58    59\n",
      "    60    61    62    63    64    65    66    67    68    69    70    71\n",
      "    72    73    74    75    76    77    78    79    80    81    82    83\n",
      "    84    85    86    87    88    89    90    91    92    93    94    95\n",
      "    96    97    98    99   100   101   102   103   104   105   106   107\n",
      "   108   109   110   111   112   113   114   115   116   117   118   119\n",
      "   120   121   122   123   124   125   126   127   128   129   130   131\n",
      "   132   133   134   135   136   137   138   139   140   141   142   143\n",
      "   144   145   146   147   148   149   150   151   152   153   154   155\n",
      "   156   157   158   159   160   161   162   163   164   165   166   167\n",
      "   168   169   170   171   172   173   174   175   176   177   178   179\n",
      "   180   181   182   183   184   185   186   187   188   189   190   191\n",
      "   192   193   194   195   196   197   198   199   200   201   202   203\n",
      "   204   205   206   207   208   209   210   211   212   213   214   215\n",
      "   216   217   218   219   220   221   222   223   224   225   226   227\n",
      "   228   229   230   231   232   233   234   235   236   237   238   239\n",
      "   240   241   242   243   244   245   246   247   248   249   250   251\n",
      "   252   253   254   255   256   257   258   259   260   261   262   264\n",
      "   265   266   267   268   269   270   271   272   273   274   275   276\n",
      "   277   278   279   280   281   282   283   284   285   286   287   288\n",
      "   289   290   292   293   294   295   296   297   298   299   300   301\n",
      "   303   304   305   306   307   308   309   310   311   313   314   315\n",
      "   316   317   318   320   321   322   323   324   325   326   327   328\n",
      "   329   330   331   332   333   334   335   336   337   338   339   340\n",
      "   341   343   344   345   346   347   348   349   350   351   352   353\n",
      "   354   355   356   357   358   360   361   362   363   364   365   367\n",
      "   368   370   371   374   375   376   377   379   380   381   382   385\n",
      "   386   387   388   390   392   394   396   398   399   400   401   402\n",
      "   405   408   409   411   416   420   421   425   426   428   430   431\n",
      "   435   440   442   445   449   450   454   457   459   460   475   476\n",
      "   485   487   489   490   500   504   505   507   508   510   514   515\n",
      "   517   519   520   521   525   530   540   541   544   550   551   553\n",
      "   560   572   574   579   580   584   585   599   600   601   602   603\n",
      "   604   606   607   610   612   620   640   645   650   651   671   678\n",
      "   682   685   696   700   702   703   732   743   750   751   754   771\n",
      "   776   800   805   808   850   851   871   900   901   902   903   907\n",
      "   909   923   950   952   953   960   998   999  1000  1001  1002  1003\n",
      "  1004  1005  1011  1012  1016  1017  1021  1024  1054  1055  1056  1062\n",
      "  1079  1082  1090  1100  1102  1103  1105  1111  1115  1120  1149  1151\n",
      "  1158  1160  1162  1164  1199  1200  1202  1221  1223  1230  1239  1240\n",
      "  1241  1250  1252  1256  1275  1288  1299  1300  1312  1317  1324  1339\n",
      "  1351  1360  1362  1363  1367  1390  1394  1398  1399  1400  1401  1403\n",
      "  1405  1416  1432  1433  1436  1500  1501  1502  1503  1506  1521  1548\n",
      "  1595  1596  1597  1598  1600  1625  1631  1653  1659  1689  1700  1701\n",
      "  1703  1704  1707  1753  1771  1779  1780  1781  1783  1793  1796  1799\n",
      "  1800  1801  1870  1895  1896  1900  1910  1920  1922  1933  1937  1968\n",
      "  1986  1988  1992  1993  1995  1998  1999  2000  2004  2005  2007  2009\n",
      "  2016  2017  2018  2172  2200  2201  2331  2340  2389  2402  2461  2598\n",
      "  2729  2789  2792  2799  3000  3199  3454  3500  3750  4400  4507  4700\n",
      "  5000  5411  5420  5575  5809  5815  5867  6006  6010  6011  6012  6018\n",
      "  6045  6062  6226  6512  6920  7508  7511  7512  7515  7518  7529  7544\n",
      "  8011  8259  8404  8500  9000  9007  9010  9011  9012  9013  9710 10000\n",
      " 10110 10218 10311 10317 10520 10522 10710 10910 10912 11011 11025 11111\n",
      " 11509 11530 11635 12012 12510 12512 12684 13616 13636 14009 15001 15016\n",
      " 15017 15020 15033 16011 16051 16311 16312 17011 17019 17410 17700 17932\n",
      " 19208 19211 19312 20000]\n",
      "\n",
      "Elementos de la columna mileage\n",
      "[  5000  10000  20000  30000  40000  50000  60000  70000  80000  90000\n",
      " 100000 125000 150000]\n",
      "\n",
      "Elementos de la columna registration_month\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "\n",
      "Elementos de la columna number_of_pictures\n",
      "[0]\n",
      "\n",
      "Elementos de la columna postal_code\n",
      "[ 1067  1068  1069 ... 99994 99996 99998]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_prev(df):\n",
    "    fig, axes =plt.subplots(ncols=4,nrows=4,figsize=[12,12])\n",
    "\n",
    "    for ax, column in zip(axes.flatten(), df.columns):\n",
    "        ax.hist(df[column].dropna(), bins=10, color='g')\n",
    "        ax.grid(True)\n",
    "        ax.set_title(column)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_prev(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Observaciones\n",
    "\n",
    "\n",
    "Al momento nos encontramos con las siguientes situaciones:\n",
    "\n",
    "Elementos nulos para las columnas:\n",
    "- vehicle_type\n",
    "- gearbox \n",
    "- model\n",
    "- fuel_type\n",
    "- not_repaired\n",
    "\n",
    "A su vez, hemos identificado incongruencias en los datos registrados para las siguientes columnas: \n",
    "\n",
    "- `price`: En los valores de precio puedo observar valores de muy bajos que pueden ser considerados `sesgos de información.`\n",
    "- `registration year` : se pueden observar ver valores superiores al año actual y valores por debajo de 1886 (cuando se creó el primer vehículo), existen muchos `datos con sesgo`.\n",
    "- `power` la medición esta en caballos de vapor. El primer vehiculo creado tenía una fuerza de CV de 0.75, por lo que es incongruente ver valores de 0 en la base de datos, en su contraparte, el vehículo con mayor velocidad de CV regitrada para 2020 fue de 1800 CV, por lo que `tenemos incongruencias` en los datos cuyos valores superan los a 10,000 CV. \n",
    "\n",
    "De un total de 16 columnas, 8 columnas se encuentran sesgadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sesgo de 'price'\n",
    "\n",
    "`- Existen precios de vehículos por debajo de los 600 dolares.`\n",
    "\n",
    "Para poder ejecutar un análisis mas profundo es necesario identificar que pudo haber pasado con los datos, una suposición sería que la base se descargo de una plataforma en línea donde los usuarios pueden decidir el precio final de su vehículo, algunos usuarios podrían optar por colocar precios irreales para llamar la atención de los compradores.\n",
    "\n",
    "Con el fin de alimentar nuestro modelo de una mejor manera, será necesario reclasificar o excluir los precios menores a 600 dolares. Este umbral se ha obtenido de la busqueda de los precios minimos y maximos para la venta de vehiculos en europa de los sitios\n",
    "- www.coches.com,\n",
    "- www.milanuncios.com\n",
    "\n",
    "Si realizaramos un filtro de precios encontrariamos 46,313 filas afectadas que representan el 13.07% del total del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sesgo de 'registration_year'\n",
    "`- Se pueden observar ver valores superiores al año actual y valores por debajo de 1886 (antes del primer automovil creado).`\n",
    "\n",
    "Siguiendo las fuentes antes mencionadas, podemos ver vehículos ofertados con fecha de registro desde 1980, mantendremos este umbral en nuestro dataset, por otra parte el registro muestra vehiculos con fecha de registro mayor a 2016, fecha en la que se descargaron estos datos. Por lo que datos posteriores no deberían de considerarse para este estudio.\n",
    "\n",
    "Considerando la depuración del umbral mínimo y máximo, sería necesario depurar 17,978 filas representando un 5.07% del total del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sesgo de 'power'\n",
    "`- Valores incongruentes en los CV, con valores inferiores a 60 y superiores a 500 en nuestra base de datos.`\n",
    "\n",
    "Para la seccion de power tenemos como entrada que el primer vehiculo construido tenía una potencia de Caballos de Vapor (CV) de 0.75. \n",
    "De acuerdo con las paginas antes mencionadas, los vehiculos pueden tener una potencia entre 60 y 400 cv\n",
    "\n",
    "\n",
    "Se obtuvieron muestras al azar los vehiculos de la base de datos con registro mayor a 400cv y ningúno clasifico con mas de 250 cv reales, por lo que limitaremos la búsqueda a 300 cv\n",
    "Si manejamos los umbrales de 60,300 tendríamos un total de 67,268  datos por de purar representando un 18.99% del dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sesgo de 'mileage'\n",
    "`- Existen vehiculos con registro de salida del año en curso y con 150,000 km registrados (datos incongruentes).`\n",
    "\n",
    "En promedio, los vehiculos generarn un kilometraje de 15,000 a 27,000 kms por año, para minimizar los datos afectados, se excluiran los autos con un kilometraje mayor a 150,000 para añós posteriores a 2011. (27 kms por añó).\n",
    "19102 filas que corresponden a un 5.39 del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "\n",
    "El dataset descargado presenta bastantes datos sesgados e incongruentes, si bien hemos establecido la hipótesis de que la base se descargo de una plataforma en línea donde los usuarios pueden decidir el precio final de su vehículo no podemos asegurar que sea correcta, sin embargo el enfoque principal del de este proyecto se basa en entrenar un modelo de predicción, por lo que será necesario excluir estos datos para tener una base de mejor calidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluyendo valores price\n",
    "recalibrate_df= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalibrate_df= recalibrate_df.query('price>=600')\n",
    "recalibrate_df = recalibrate_df.query(' 1980 < registration_year < 2017')\n",
    "recalibrate_df = recalibrate_df.query('60 <=power <=300')\n",
    "recalibrate_df = recalibrate_df.query('~(registration_year>=2012 and mileage >= 150000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha depurado un 30.42 de la data original\n"
     ]
    }
   ],
   "source": [
    "loss_data = (1 - (recalibrate_df.shape[0] / df.shape[0])) *100\n",
    "print(f'Se ha depurado un {loss_data:.2f} de la data original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_repaired          30254\n",
       "fuel_type              9408\n",
       "model                  7475\n",
       "vehicle_type           3932\n",
       "gearbox                3357\n",
       "date_crawled              0\n",
       "price                     0\n",
       "registration_year         0\n",
       "power                     0\n",
       "mileage                   0\n",
       "registration_month        0\n",
       "brand                     0\n",
       "date_created              0\n",
       "number_of_pictures        0\n",
       "postal_code               0\n",
       "last_seen                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalibrate_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_prev(recalibrate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos cambios las columnas de 'power' y de 'registration_year' mejoraron su coherencia. El kilometraje sigue estando alto para autos con valores de recorrido mayor a 150,000, sin embargo, de acuerdo con la información externa, esta puede entrar en el umbral de 27,000 kms por año."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores nuloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la manipulación de los valores nulos, se han analizado las siguientes opciones:\n",
    "`- Eliminación de filas o columnas con valores nulos`\n",
    "- Imputación de valores nulos\n",
    "- Uso de modelos de imputación\n",
    "- Codificación de valores nulos\n",
    "\n",
    "Inicialmente se optó por modelos de imputación sin embargo el peso de la base de datos no permitio generar las predicciones necesarias, por lo que se optará por la eliminación de filas con valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputated_df = recalibrate_df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mantenemos las columnas que realmente nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputated_df = imputated_df.drop(columns=['date_crawled','date_created','number_of_pictures', 'last_seen','postal_code'])\n",
    "\n",
    "# chart_prev(imputated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261853</th>\n",
       "      <td>6990</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>170</td>\n",
       "      <td>c5</td>\n",
       "      <td>150000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>citroen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322611</th>\n",
       "      <td>11300</td>\n",
       "      <td>wagon</td>\n",
       "      <td>2010</td>\n",
       "      <td>manual</td>\n",
       "      <td>102</td>\n",
       "      <td>a3</td>\n",
       "      <td>100000</td>\n",
       "      <td>11</td>\n",
       "      <td>petrol</td>\n",
       "      <td>audi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156697</th>\n",
       "      <td>11900</td>\n",
       "      <td>small</td>\n",
       "      <td>2013</td>\n",
       "      <td>manual</td>\n",
       "      <td>120</td>\n",
       "      <td>2_reihe</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "      <td>petrol</td>\n",
       "      <td>peugeot</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227133</th>\n",
       "      <td>3333</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>76</td>\n",
       "      <td>twingo</td>\n",
       "      <td>100000</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>renault</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59100</th>\n",
       "      <td>2500</td>\n",
       "      <td>sedan</td>\n",
       "      <td>2003</td>\n",
       "      <td>manual</td>\n",
       "      <td>116</td>\n",
       "      <td>bora</td>\n",
       "      <td>150000</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price vehicle_type  registration_year gearbox  power    model  \\\n",
       "261853   6990        wagon               2008  manual    170       c5   \n",
       "322611  11300        wagon               2010  manual    102       a3   \n",
       "156697  11900        small               2013  manual    120  2_reihe   \n",
       "227133   3333        small               2008  manual     76   twingo   \n",
       "59100    2500        sedan               2003  manual    116     bora   \n",
       "\n",
       "        mileage  registration_month fuel_type       brand  not_repaired  \n",
       "261853   150000                   7  gasoline     citroen           0.0  \n",
       "322611   100000                  11    petrol        audi           0.0  \n",
       "156697    40000                   1    petrol     peugeot           0.0  \n",
       "227133   100000                   5    petrol     renault           0.0  \n",
       "59100    150000                   3    petrol  volkswagen           0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputated_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transformación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la funciones necesarias para la tranformación de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE(df):\n",
    "    '''Esta funcion recibira un dataframe con columnas categóricas y devolverá su version codificada en multiples columnas binarias'''\n",
    "    encoder = OneHotEncoder(drop='first')\n",
    "    encoded_data = encoder.fit_transform(df)\n",
    "    output_names = encoder.get_feature_names_out(df.columns)\n",
    "    df_codified = pd.DataFrame(encoded_data.toarray(), columns=output_names, index= df.index)\n",
    "    return df_codified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(X_train, X_test):\n",
    "    '''Esta función procesara las caracteristicas de entrenamiento y devolverá un escalamiento de los datos numéricos'''\n",
    "    int_names = X_train.select_dtypes(include=['int']).columns\n",
    "    model =  StandardScaler()\n",
    "    X_train[int_names] = model.fit_transform(X_train[int_names])\n",
    "    X_test[int_names] = model.transform(X_test[int_names])\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos OHE a los valores categórigos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = imputated_df.select_dtypes(include=['object']).columns\n",
    "new_cols = OHE(imputated_df[obj_cols])\n",
    "\n",
    "imputated_df =imputated_df.drop(columns=obj_cols)\n",
    "imputated_df = pd.concat([imputated_df, new_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestras características y nuestros objectivos para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputated_df.drop(columns=['price'])\n",
    "y = imputated_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando si los elementos fueron procesados correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registration_year</th>\n",
       "      <th>power</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>vehicle_type_convertible</th>\n",
       "      <th>vehicle_type_coupe</th>\n",
       "      <th>vehicle_type_other</th>\n",
       "      <th>vehicle_type_sedan</th>\n",
       "      <th>vehicle_type_small</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_rover</th>\n",
       "      <th>brand_saab</th>\n",
       "      <th>brand_seat</th>\n",
       "      <th>brand_skoda</th>\n",
       "      <th>brand_smart</th>\n",
       "      <th>brand_subaru</th>\n",
       "      <th>brand_suzuki</th>\n",
       "      <th>brand_toyota</th>\n",
       "      <th>brand_volkswagen</th>\n",
       "      <th>brand_volvo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>75</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>69</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1995</td>\n",
       "      <td>102</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004</td>\n",
       "      <td>109</td>\n",
       "      <td>150000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004</td>\n",
       "      <td>105</td>\n",
       "      <td>150000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    registration_year  power  mileage  registration_month  not_repaired  \\\n",
       "3                2001     75   150000                   6           0.0   \n",
       "4                2008     69    90000                   7           0.0   \n",
       "5                1995    102   150000                  10           1.0   \n",
       "6                2004    109   150000                   8           0.0   \n",
       "10               2004    105   150000                  12           0.0   \n",
       "\n",
       "    vehicle_type_convertible  vehicle_type_coupe  vehicle_type_other  \\\n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        0.0                 0.0                 0.0   \n",
       "5                        0.0                 0.0                 0.0   \n",
       "6                        1.0                 0.0                 0.0   \n",
       "10                       0.0                 0.0                 0.0   \n",
       "\n",
       "    vehicle_type_sedan  vehicle_type_small  ...  brand_rover  brand_saab  \\\n",
       "3                  0.0                 1.0  ...          0.0         0.0   \n",
       "4                  0.0                 1.0  ...          0.0         0.0   \n",
       "5                  1.0                 0.0  ...          0.0         0.0   \n",
       "6                  0.0                 0.0  ...          0.0         0.0   \n",
       "10                 1.0                 0.0  ...          0.0         0.0   \n",
       "\n",
       "    brand_seat  brand_skoda  brand_smart  brand_subaru  brand_suzuki  \\\n",
       "3          0.0          0.0          0.0           0.0           0.0   \n",
       "4          0.0          1.0          0.0           0.0           0.0   \n",
       "5          0.0          0.0          0.0           0.0           0.0   \n",
       "6          0.0          0.0          0.0           0.0           0.0   \n",
       "10         0.0          0.0          0.0           0.0           0.0   \n",
       "\n",
       "    brand_toyota  brand_volkswagen  brand_volvo  \n",
       "3            0.0               1.0          0.0  \n",
       "4            0.0               0.0          0.0  \n",
       "5            0.0               0.0          0.0  \n",
       "6            0.0               0.0          0.0  \n",
       "10           0.0               0.0          0.0  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     1500\n",
       "4     3600\n",
       "5      650\n",
       "6     2200\n",
       "10    2000\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenarán los modelos 'Linear_Regression', 'Random_Forest', 'LightGBM', 'Catboost' y 'XGboost' para comparar los mejores resultados del RMSE. Los primeros 3 elementos usaran la función model_training. Para los modelos 'Catboost' 'XGboost' los entrenamientos se realizarán con código independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X,y, model, params):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=100) \n",
    "    X_train, X_test = scaler(X_train, X_test)\n",
    "\n",
    "    grid_search = GridSearchCV(model, params, scoring='neg_root_mean_squared_error', cv=5, verbose=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente variable 'times', nos permitirá conocer el tiempo de ejecución de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END ............fit_intercept=True;, score=-2296.642 total time=  10.8s\n",
      "[CV 2/5] END ............fit_intercept=True;, score=-2308.902 total time=  10.9s\n",
      "[CV 3/5] END ............fit_intercept=True;, score=-2297.597 total time=  10.7s\n",
      "[CV 4/5] END ............fit_intercept=True;, score=-2286.359 total time=  10.2s\n",
      "[CV 5/5] END ............fit_intercept=True;, score=-2312.306 total time=  10.0s\n",
      "[CV 1/5] END ...........fit_intercept=False;, score=-2300.274 total time=  11.3s\n",
      "[CV 2/5] END ...........fit_intercept=False;, score=-2312.251 total time=   7.2s\n",
      "[CV 3/5] END ...........fit_intercept=False;, score=-2300.640 total time=   4.8s\n",
      "[CV 4/5] END ...........fit_intercept=False;, score=-2289.403 total time=   4.4s\n",
      "[CV 5/5] END ...........fit_intercept=False;, score=-2315.262 total time=   5.0s\n",
      "\n",
      "\n",
      "Tiempo de ejecución: 93.02 segundos\n",
      "RMSE en el conjunto de entrenamiento (Linear Regression): 2305.9333785873855\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = LinearRegression()\n",
    "params = {\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "rmse_lr = model_training(X,y,model,params)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "\n",
    "times.append({'Modelo':'Linear Regression','RMSE':rmse_lr,'Tiempo':elapsed_time})\n",
    "\n",
    "print('\\n')\n",
    "print(f'Tiempo de ejecución: {elapsed_time:.2f} segundos')\n",
    "print(\"RMSE en el conjunto de entrenamiento (Linear Regression):\", rmse_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosque Aleatorio (Regresión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ...............n_estimators=10;, score=-1598.319 total time=  21.4s\n",
      "[CV 2/5] END ...............n_estimators=10;, score=-1598.641 total time=  21.0s\n",
      "[CV 3/5] END ...............n_estimators=10;, score=-1596.968 total time=  20.8s\n",
      "[CV 4/5] END ...............n_estimators=10;, score=-1608.618 total time=  20.5s\n",
      "[CV 5/5] END ...............n_estimators=10;, score=-1614.533 total time=  20.7s\n",
      "\n",
      "\n",
      "Tiempo de ejecución: 132.95 segundos\n",
      "RMSE en el conjunto de entrenamiento (Random Forest): 1576.3102511586826\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model = RandomForestRegressor(random_state=100)\n",
    "params = {\n",
    "    'n_estimators': [10],\n",
    "    # 'n_estimators': [10,20,100],\n",
    "    # 'max_depth': [None, 10,20]\n",
    "    # 'min_samples_split': [2,10],\n",
    "    # 'min_samples_leaf': [1,4]\n",
    "}\n",
    "rmse_rf = model_training(X,y,model,params)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "times.append({'Modelo':'Random_Forest','RMSE':rmse_rf,'Tiempo':elapsed_time})\n",
    "\n",
    "print('\\n')\n",
    "print(f'Tiempo de ejecución: {elapsed_time:.2f} segundos')\n",
    "print(\"RMSE en el conjunto de entrenamiento (Random Forest):\", rmse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jm_he\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\jm_he\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50;, score=-1914.959 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50;, score=-1921.148 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50;, score=-1897.818 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50;, score=-1910.176 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50;, score=-1925.181 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100;, score=-1702.643 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100;, score=-1702.541 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100;, score=-1689.059 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100;, score=-1696.919 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100;, score=-1710.570 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50;, score=-1704.184 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50;, score=-1700.988 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50;, score=-1683.962 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50;, score=-1701.389 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50;, score=-1708.028 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100;, score=-1618.039 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100;, score=-1614.186 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100;, score=-1596.570 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100;, score=-1613.060 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100;, score=-1620.303 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50;, score=-1625.530 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50;, score=-1618.066 total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50;, score=-1605.902 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50;, score=-1617.689 total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50;, score=-1626.167 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100;, score=-1566.540 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100;, score=-1562.615 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100;, score=-1553.104 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100;, score=-1563.428 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100;, score=-1572.728 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=dart, learning_rate=0.05, n_estimators=50;, score=-3413.485 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=dart, learning_rate=0.05, n_estimators=50;, score=-3448.453 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=dart, learning_rate=0.05, n_estimators=50;, score=-3400.512 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=dart, learning_rate=0.05, n_estimators=50;, score=-3429.187 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=dart, learning_rate=0.05, n_estimators=50;, score=-3419.094 total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=dart, learning_rate=0.05, n_estimators=100;, score=-2657.175 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=dart, learning_rate=0.05, n_estimators=100;, score=-2684.231 total time=   3.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=dart, learning_rate=0.05, n_estimators=100;, score=-2642.110 total time=   3.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=dart, learning_rate=0.05, n_estimators=100;, score=-2664.501 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=dart, learning_rate=0.05, n_estimators=100;, score=-2663.278 total time=   3.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=dart, learning_rate=0.1, n_estimators=50;, score=-2483.040 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=dart, learning_rate=0.1, n_estimators=50;, score=-2508.746 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=dart, learning_rate=0.1, n_estimators=50;, score=-2468.240 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=dart, learning_rate=0.1, n_estimators=50;, score=-2492.613 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=dart, learning_rate=0.1, n_estimators=50;, score=-2491.935 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=dart, learning_rate=0.1, n_estimators=100;, score=-2002.031 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=dart, learning_rate=0.1, n_estimators=100;, score=-2017.263 total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=dart, learning_rate=0.1, n_estimators=100;, score=-1985.739 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=dart, learning_rate=0.1, n_estimators=100;, score=-2002.788 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=dart, learning_rate=0.1, n_estimators=100;, score=-2007.897 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=dart, learning_rate=0.2, n_estimators=50;, score=-1909.220 total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=dart, learning_rate=0.2, n_estimators=50;, score=-1921.958 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=dart, learning_rate=0.2, n_estimators=50;, score=-1897.001 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=dart, learning_rate=0.2, n_estimators=50;, score=-1913.908 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=dart, learning_rate=0.2, n_estimators=50;, score=-1915.138 total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5690.157899\n",
      "[CV 1/5] END boosting_type=dart, learning_rate=0.2, n_estimators=100;, score=-1712.487 total time=   3.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5687.642719\n",
      "[CV 2/5] END boosting_type=dart, learning_rate=0.2, n_estimators=100;, score=-1718.008 total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5691.245126\n",
      "[CV 3/5] END boosting_type=dart, learning_rate=0.2, n_estimators=100;, score=-1695.563 total time=   3.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 271\n",
      "[LightGBM] [Info] Start training from score 5681.404335\n",
      "[CV 4/5] END boosting_type=dart, learning_rate=0.2, n_estimators=100;, score=-1711.808 total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 824\n",
      "[LightGBM] [Info] Number of data points in the train set: 122072, number of used features: 274\n",
      "[LightGBM] [Info] Start training from score 5689.261174\n",
      "[CV 5/5] END boosting_type=dart, learning_rate=0.2, n_estimators=100;, score=-1718.752 total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 833\n",
      "[LightGBM] [Info] Number of data points in the train set: 152590, number of used features: 276\n",
      "[LightGBM] [Info] Start training from score 5687.942250\n",
      "\n",
      "\n",
      "Tiempo de ejecución: 163.99 segundos\n",
      "RMSE en el conjunto de entrenamiento (Lightgbm): 1564.1727693857558\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "y= imputated_df['price']\n",
    "model = LGBMRegressor(objective='regression', metric='rmse', random_state=100)\n",
    "params = {\n",
    "\n",
    "    'boosting_type': ['gbdt','dart'],\n",
    "    # 'num_leaves': [20,30,40],\n",
    "    'learning_rate': [0.05,0.1,0.2],\n",
    "    'n_estimators': [50,100]\n",
    "\n",
    "    # 'boosting_type': ['gbdt','dart'],\n",
    "    # 'num_leaves': [20,30,40],\n",
    "    # 'learning_rate': [0.05,0.1,0.2],\n",
    "    # 'n_estimators': [50,100,200]\n",
    "}\n",
    "rmse_lgbm = model_training(X,y,model,params)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "times.append({'Modelo':'Light_GBM','RMSE':rmse_lgbm,'Tiempo':elapsed_time})\n",
    "\n",
    "print('\\n')\n",
    "print(f'Tiempo de ejecución: {elapsed_time:.2f} segundos')\n",
    "print(\"RMSE en el conjunto de entrenamiento (Lightgbm):\", rmse_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tiempo de ejecución: 18.28 segundos\n",
      "RMSE en el conjunto de entrenamiento (CatBoost): 1527.0330315524154\n",
      "RMSE en el conjunto de prueba (CatBoost): 1563.529273376928\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Inicializar el modelo de CatBoost\n",
    "catboost_model = CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=6, loss_function='RMSE', verbose=0)\n",
    "\n",
    "# Entrenar el modelo de CatBoost\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=100) \n",
    "X_train, X_test = scaler(X_train, X_test)\n",
    "\n",
    "catboost_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "\n",
    "# Predecir sobre el conjunto de entrenamiento y prueba\n",
    "y_train_pred_catboost = catboost_model.predict(X_train)\n",
    "y_test_pred_catboost = catboost_model.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (RMSE) en el conjunto de entrenamiento y prueba\n",
    "rmse_train_catboost = sqrt(mean_squared_error(y_train, y_train_pred_catboost))\n",
    "rmse_test_catboost = sqrt(mean_squared_error(y_test, y_test_pred_catboost))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "times.append({'Modelo':'Catboost','RMSE':rmse_test_catboost,'Tiempo':elapsed_time})\n",
    "\n",
    "print('\\n')\n",
    "print(f'Tiempo de ejecución: {elapsed_time:.2f} segundos')\n",
    "print(\"RMSE en el conjunto de entrenamiento (CatBoost):\", rmse_train_catboost)\n",
    "print(\"RMSE en el conjunto de prueba (CatBoost):\", rmse_test_catboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4307.30326\ttest-rmse:4307.70386\n",
      "[100]\ttrain-rmse:1588.82314\ttest-rmse:1630.02950\n",
      "[200]\ttrain-rmse:1518.22112\ttest-rmse:1577.58946\n",
      "[300]\ttrain-rmse:1474.17489\ttest-rmse:1548.39210\n",
      "[400]\ttrain-rmse:1439.96363\ttest-rmse:1527.82914\n",
      "[500]\ttrain-rmse:1411.60735\ttest-rmse:1513.81693\n",
      "[600]\ttrain-rmse:1387.14323\ttest-rmse:1501.99304\n",
      "[700]\ttrain-rmse:1366.31467\ttest-rmse:1492.90538\n",
      "[800]\ttrain-rmse:1348.29044\ttest-rmse:1486.57075\n",
      "[900]\ttrain-rmse:1332.72549\ttest-rmse:1481.61230\n",
      "[999]\ttrain-rmse:1316.90864\ttest-rmse:1476.86578\n",
      "\n",
      "\n",
      "Tiempo de ejecución: 37.11 segundos\n",
      "RMSE en el conjunto de entrenamiento (XGBoost): 1316.9086390799503\n",
      "RMSE en el conjunto de prueba (XGBoost): 1476.8657840883823\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Convertir los conjuntos de datos a formato DMatrix de XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Definir los parámetros del modelo\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8\n",
    "}\n",
    "\n",
    "# Entrenar el modelo de XGBoost\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=1000, evals=[(dtrain, 'train'), (dtest, 'test')], early_stopping_rounds=100, verbose_eval=100)\n",
    "\n",
    "# Predecir sobre el conjunto de entrenamiento y prueba\n",
    "y_train_pred_xgb = xgb_model.predict(dtrain)\n",
    "y_test_pred_xgb = xgb_model.predict(dtest)\n",
    "\n",
    "# Calcular el error cuadrático medio (RMSE) en el conjunto de entrenamiento y prueba\n",
    "rmse_train_xgb = sqrt(mean_squared_error(y_train, y_train_pred_xgb))\n",
    "rmse_test_xgb = sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "times.append({'Modelo':'XGBoost','RMSE':rmse_test_xgb,'Tiempo':elapsed_time})\n",
    "\n",
    "print('\\n')\n",
    "print(f'Tiempo de ejecución: {elapsed_time:.2f} segundos')\n",
    "print(\"RMSE en el conjunto de entrenamiento (XGBoost):\", rmse_train_xgb)\n",
    "print(\"RMSE en el conjunto de prueba (XGBoost):\", rmse_test_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Tiempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1476.865784</td>\n",
       "      <td>37.108805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>1563.529273</td>\n",
       "      <td>18.281880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Light_GBM</td>\n",
       "      <td>1564.172769</td>\n",
       "      <td>163.987820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>1576.310251</td>\n",
       "      <td>132.953465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2305.933379</td>\n",
       "      <td>93.019858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo         RMSE      Tiempo\n",
       "0            XGBoost  1476.865784   37.108805\n",
       "1           Catboost  1563.529273   18.281880\n",
       "2          Light_GBM  1564.172769  163.987820\n",
       "3      Random_Forest  1576.310251  132.953465\n",
       "4  Linear Regression  2305.933379   93.019858"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(times).sort_values(by='RMSE').reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Durante la preparación de los datos, se identificaron 5 columnas con valores nulos y otras 3 con datos incongruentes, dada la robustes de la base de datos se concluyó excluir las filas de los valores afectados.\n",
    "\n",
    "La codificación de valores categóricos a través de OHE y la escala de los valores numéricos fueron aplicados durante el desarrollo de los modelos.\n",
    "\n",
    "De acuerdo a los resultados mostrados en el dataframe, XGBoost es el modelo con mejor RMSE con un umbral de predicción de 1476 euros, seguido de Catboost y Light_GBM. En conclusión los modelos de potenciación de gradiente tuvieron mejores desempeños que aquellos que no lo aplican. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe 'x' para verificar. Luego presiona Shift+Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook está abierto\n",
    "- [x]  El código no tiene errores\n",
    "- [x]  Las celdas con el código han sido colocadas en orden de ejecución\n",
    "- [x]  Los datos han sido descargados y preparados\n",
    "- [x] Los modelos han sido entrenados\n",
    "- [x]  Se realizó el análisis de velocidad y calidad de los modelos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
